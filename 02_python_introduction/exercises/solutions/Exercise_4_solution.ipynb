{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "ACCEPTED_SITES = ['Skin','Oral','Feces']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Create the pipeline script and check the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['analyse_microbial_samples.py', 'Skin', '../files/exercise_4/Human_Microbiome_Project/', './results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sys.argv) < 4:\n",
    "\tprint(\"Need at least 3 arguments: <body site> <dataset path> <output path>\")\n",
    "\tsys.exit()\n",
    "\n",
    "body_site = sys.argv[1]\t\n",
    "\n",
    "if body_site not in ACCEPTED_SITES:\n",
    "\tprint(\"First argument has to be one of the following %s\" % ACCEPTED_SITES)\n",
    "\tsys.exit()\n",
    "\n",
    "dataset_path = sys.argv[2]\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "\tprint(\"Dataset path does not exist!\")\n",
    "\tsys.exit()\n",
    "\n",
    "output_path = sys.argv[3]\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "\tprint(\"Will create new output path\")\n",
    "\tos.makedirs(output_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Filter samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name = os.path.join(output_path, \"filtered_samples.txt\")\n",
    "\n",
    "unix_cmd = 'cat ' + dataset_path + '/*' + ' | grep ' + body_site + '> ' + output_file_name\n",
    "\n",
    "subprocess.call(unix_cmd,shell=True)\n",
    "\n",
    "print(\"#Saved %s samples in %s\" % (body_site, output_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 General data set statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the abundances without the body site identifier in the first column\n",
    "# 1. read the data with genfromtxt\n",
    "abundance_matrix = np.genfromtxt(output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. remove the first colum by array slicing\n",
    "abundance_matrix = abundance_matrix[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_no = abundance_matrix.shape[0]\n",
    "print(\"#Found %d %s samples\" % (sample_no,body_site))\n",
    "\n",
    "microbe_no = abundance_matrix.shape[1]\n",
    "print(\"#Found %d %s microbes\" % (microbe_no,body_site))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report sorted abundances for samples\n",
    "sample_sums = abundance_matrix.sum(1)\n",
    "sorted_sums = sorted(sample_sums, reverse=True)\n",
    "\n",
    "print(\"\\n#Summed sample abundance:\")\n",
    "print(sorted_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get microbe identfiers\n",
    "# adapt file path below\n",
    "with open(\"../files/exercise_4/microbe_identifiers.txt\",'r') as id_file:\n",
    "    identfiers = id_file.readline()\n",
    "\n",
    "identfiers = identfiers.split()\n",
    "microbe_means = abundance_matrix.mean(0)\n",
    "\n",
    "# zip to join microbe names and abundances\n",
    "joined_list = list(zip(identfiers, microbe_means))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n#Mean abundance for all microbes:\")\n",
    "for identifier, mean_abundance in joined_list:\n",
    "    print(identifier, mean_abundance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra: report by highest incidence\n",
    "print(\"\\n#The 10 microbes with highest abundance:\")\n",
    "\n",
    "from operator import itemgetter\n",
    "joined_list.sort(reverse=True, key=itemgetter(1))\n",
    "\n",
    "for name, mean_abundance in joined_list[:10]:\n",
    "    print(name, mean_abundance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Microbial interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute microbial interaction script\n",
    "# adapt path if needed\n",
    "unix_command = \"python ../files/exercise_4/compute_microbial_interactions.py \" + output_file_name\n",
    "subprocess.run(unix_command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve interaction file\n",
    "expected_file_name = \"pairwise_interaction_strengths.txt\"\n",
    "output_file_name = os.path.join(output_path, expected_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n#Strongest positive and the strongest negative interaction partner:\")\n",
    "\n",
    "# loop through all the lines in the interaction file\n",
    "with open(output_file_name,'r') as f:\n",
    "\n",
    "    # Keep track of the current row/line to avoid self-relationships\n",
    "    current_idx = 0\n",
    "    for line in f:\n",
    "\n",
    "        # Initialize two pairs of variables to store the strongest:\n",
    "\n",
    "        # negative interaction partner\n",
    "        min_val = 2.0\n",
    "        min_idx = -1\n",
    "\n",
    "        # positive interaction partner\n",
    "        max_val = -2.0\n",
    "        max_idx = -1\n",
    "\n",
    "        # use the built-in enumerate function to return both element and index\n",
    "        for idx, element in enumerate(line.rstrip().split()):\n",
    "\n",
    "            # transform the elmenent into a floating point value\n",
    "            val = float(element)\n",
    "\n",
    "            if idx == current_idx:\n",
    "                # skip self-interactions\n",
    "                continue\n",
    "\n",
    "            if val > max_val:\n",
    "                max_val = val\n",
    "                max_idx = idx\n",
    "\n",
    "            if val < min_val:\n",
    "                min_val = val\n",
    "                min_idx = idx\n",
    "\n",
    "        # Output the desired result\n",
    "        print(identfiers[current_idx], \":\", identfiers[max_idx], \"(\", max_val, \");\", identfiers[min_idx], \"(\", min_val, \")\")\n",
    "\n",
    "        # Update the current line/row index\n",
    "        current_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: computing correlations with numpy and timing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation function from compute_microbial_interactions.py\n",
    "import math\n",
    "\n",
    "def infer_interactions(data_set):\n",
    "    number_samples = len(data_set)\n",
    "    number_otus = len(data_set[0])\n",
    "    otu_freqs = [0] * number_otus\n",
    "    for data_row in data_set:\n",
    "        for i in range(len(data_row)):\n",
    "            otu_freqs[i] += data_row[i]\n",
    "\n",
    "    mean_freqs = [freq / float(number_samples) for freq in otu_freqs]\n",
    "\n",
    "    var_covar_matrix = [[0.0] * number_otus for i in range(number_otus)]\n",
    "    for i in range(number_otus):\n",
    "        for j in range(number_otus):\n",
    "            for k in range(number_samples):\n",
    "                var_covar_matrix[i][j] += (data_set[k][i] - mean_freqs[i]) * (data_set[k][j] - mean_freqs[j])\n",
    "\n",
    "    for i in range(number_otus):\n",
    "        for j in range(number_otus):\n",
    "            var_covar_matrix[i][j] = var_covar_matrix[i][j] / number_samples\n",
    "\n",
    "\n",
    "    interaction_matrix = [[0.0] * number_otus for i in range(number_otus)]\n",
    "    for i in range(number_otus):\n",
    "        for j in range(number_otus):\n",
    "            cov_ij = var_covar_matrix[i][j]\n",
    "            std_i = math.sqrt(var_covar_matrix[i][i])\n",
    "            std_j = math.sqrt(var_covar_matrix[j][j])\n",
    "\n",
    "            denom = (std_i * std_j)\n",
    "\n",
    "            if denom == 0:\n",
    "                interaction_matrix[i][j] = 0.0\n",
    "            else:\n",
    "                interaction_matrix[i][j] = cov_ij / (std_i * std_j)\n",
    "\n",
    "    return interaction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time it\n",
    "\n",
    "print(\"\\nTiming for naive correlation function:\")\n",
    "\n",
    "## with the ipython shell:\n",
    "#%timeit  np.corrcoef(abundance_matrix, rowvar=0)\n",
    "\n",
    "## within this script its slightly more complicated:\n",
    "from IPython import get_ipython\n",
    "ipython = get_ipython()\n",
    "ipython.run_line_magic(\"timeit\", \"infer_interactions(abundance_matrix)\")\n",
    "\n",
    "\n",
    "print(\"\\nTiming for numpy correlations:\")\n",
    "# compare to timing from numpy function\n",
    "#%timeit  np.corrcoef(abundance_matrix, rowvar=0) # OR\n",
    "ipython.run_line_magic(\"timeit\", \"np.corrcoef(abundance_matrix, rowvar=0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
